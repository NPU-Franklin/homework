{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Classification With DNN\n",
    "\n",
    "To classify 10 kinds of different clothes with DNN"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1. Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Importing……\nImport complete!\n\nChecking Tensorflow version:\n2.0.0\n"
    }
   ],
   "source": [
    "print(\"Importing……\")\n",
    "\n",
    "# import Tensorflow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.python.keras.layers.normalization import BatchNormalization\n",
    "from tensorflow.python.keras.layers.convolutional import Conv2D, AveragePooling2D, MaxPooling2D, ZeroPadding2D\n",
    "from tensorflow.python.keras.layers.core import Activation, Flatten, Dense, Dropout\n",
    "from tensorflow.python.keras.layers import Input, add\n",
    "from tensorflow.python.keras.models import Model\n",
    "from tensorflow.python.keras.regularizers import l2\n",
    "from tensorflow.python.keras.initializers import glorot_uniform\n",
    "from tensorflow.python.keras.utils.vis_utils import plot_model\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "\n",
    "print(\"Import complete!\\n\")\n",
    "print(\"Checking Tensorflow version:\")\n",
    "# Check Tensorflow version\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2. Load MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Loading train and test data……\n\nLoading complete!\n"
    }
   ],
   "source": [
    "# import the Fashion MNIST dataset\n",
    "print(\"Loading train and test data……\\n\")\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "print(\"Loading complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Scaling the feature.\n"
    }
   ],
   "source": [
    "# Feature scaling\n",
    "print(\"Scaling the feature.\")\n",
    "train_images = train_images / 255.0\n",
    "\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 4. Build the training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Start to build the model……\n\nBuild complete!\n\nSummary of the model:\nModel: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nflatten (Flatten)            (None, 784)               0         \n_________________________________________________________________\ndense (Dense)                (None, 128)               100480    \n_________________________________________________________________\ndense_1 (Dense)              (None, 128)               16512     \n_________________________________________________________________\ndense_2 (Dense)              (None, 10)                1290      \n=================================================================\nTotal params: 118,282\nTrainable params: 118,282\nNon-trainable params: 0\n_________________________________________________________________\nNone\n"
    }
   ],
   "source": [
    "# Build the training model(DNN)\n",
    "print(\"Start to build the model……\\n\")\n",
    "model = keras.Sequential()\n",
    "\n",
    "model.add(Flatten(input_shape=(28, 28)))\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "print(\"Build complete!\\n\")\n",
    "# look through the summary of the model\n",
    "print(\"Summary of the model:\")\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 5. Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Compiling……\nCompiling complete!\n"
    }
   ],
   "source": [
    "print(\"Compiling……\")\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "print(\"Compiling complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 6. Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Training:\nTrain on 60000 samples\nEpoch 1/15\n60000/60000 [==============================] - 6s 93us/sample - loss: 0.4797 - accuracy: 0.8290\nEpoch 2/15\n60000/60000 [==============================] - 4s 73us/sample - loss: 0.3609 - accuracy: 0.8687\nEpoch 3/15\n60000/60000 [==============================] - 4s 71us/sample - loss: 0.3283 - accuracy: 0.8781\nEpoch 4/15\n60000/60000 [==============================] - 4s 71us/sample - loss: 0.3049 - accuracy: 0.8871\nEpoch 5/15\n60000/60000 [==============================] - 4s 74us/sample - loss: 0.2877 - accuracy: 0.8929\nEpoch 6/15\n60000/60000 [==============================] - 4s 74us/sample - loss: 0.2735 - accuracy: 0.8982\nEpoch 7/15\n60000/60000 [==============================] - 4s 74us/sample - loss: 0.2619 - accuracy: 0.9024\nEpoch 8/15\n60000/60000 [==============================] - 4s 74us/sample - loss: 0.2505 - accuracy: 0.9053\nEpoch 9/15\n60000/60000 [==============================] - 4s 74us/sample - loss: 0.2409 - accuracy: 0.9096\nEpoch 10/15\n60000/60000 [==============================] - 4s 75us/sample - loss: 0.2293 - accuracy: 0.9126\nEpoch 11/15\n60000/60000 [==============================] - 5s 75us/sample - loss: 0.2238 - accuracy: 0.9147\nEpoch 12/15\n60000/60000 [==============================] - 5s 78us/sample - loss: 0.2161 - accuracy: 0.9182\nEpoch 13/15\n60000/60000 [==============================] - 5s 77us/sample - loss: 0.2067 - accuracy: 0.9201\nEpoch 14/15\n60000/60000 [==============================] - 5s 78us/sample - loss: 0.2026 - accuracy: 0.9229\nEpoch 15/15\n60000/60000 [==============================] - 5s 76us/sample - loss: 0.1942 - accuracy: 0.9256\nTraining complete!\n"
    }
   ],
   "source": [
    "# Train the model\n",
    "print(\"Training:\")\n",
    "model.fit(train_images, train_labels, epochs=35)\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 7. Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Evaluating:\n10000/1 - 1s - loss: 0.3064 - accuracy: 0.8859\n\nTest loss: 0.3567207415580749\n\nTest accuracy: 0.8859\n"
    }
   ],
   "source": [
    "# Evaluate accuracy\n",
    "print(\"Evaluating:\")\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)\n",
    "\n",
    "print(\"\\nTest loss:\", test_loss)\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 8. Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Saving model to disk…… \n\nComplete!\n\n"
    }
   ],
   "source": [
    "# Save model\n",
    "print(\"Saving model to disk…… \\n\")\n",
    "mp = \"./homework/DNN.h5\"\n",
    "model.save(mp)\n",
    "print(\"Complete!\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 9. Exploring the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Reading model:\nMatrix of dense_0_bias：\n0.35881642\n\nMatrix of dense_0_kernel：\n[[ 0.00741668 -0.05267666  0.05012955 ... -0.22978176 -0.15938324\n  -0.0485287 ]\n [-0.10028731  0.03870839 -0.2824214  ...  0.0597631   0.02805478\n  -0.25367033]\n [-0.12349754 -0.08467785 -0.4063141  ...  0.23210849 -0.26459134\n  -0.18943773]\n ...\n [ 0.16377544 -0.3634908   0.12976293 ...  0.23814683  0.00419304\n  -0.04964558]\n [-0.13105942 -0.26130098  0.1505496  ...  0.71819615 -0.09555394\n   0.08085402]\n [ 0.05384517 -0.24763876 -0.40728837 ... -0.06735456 -0.03420549\n   0.19146696]]\n\nMatrix of dense_1_bias：\n0.094595216\n\nMatrix of dense_1_kernel：\n[[-0.12695728 -0.01211365  0.03051919 ... -0.18435039  0.08223659\n   0.07917549]\n [ 0.06033992 -0.04472876 -0.00463622 ...  0.22569524  0.06749533\n   0.11293988]\n [ 0.27966934  0.10332545  0.04868623 ... -0.23233567  0.07579949\n   0.02886694]\n ...\n [ 0.04466292 -0.1844849  -0.41768304 ...  0.3360146   0.14692868\n   0.008058  ]\n [ 0.22809228  0.10250816 -0.0960591  ...  0.08868193  0.02787782\n   0.00691942]\n [-0.15489341  0.06711     0.04371097 ...  0.1229307   0.14836884\n   0.05450646]]\n\nMatrix of dense_2_bias：\n-0.19458757\n\nMatrix of dense_2_kernel：\n[[ 0.16189091  0.18941696 -0.00943119 ... -0.99450195 -0.2685119\n  -0.52057993]\n [ 0.05457783 -0.0052361  -0.07246746 ... -0.95841223  0.13005202\n  -0.44977787]\n [-0.22160774 -0.6939037  -0.07460847 ... -0.795238   -0.43458983\n  -0.28244704]\n ...\n [-0.03953679 -0.6537381   0.15933886 ...  0.06037195  0.11952522\n   0.06558847]\n [-0.20861939 -0.44002005 -0.06453014 ... -0.36601344  0.1812937\n   0.19968893]\n [ 0.04478313 -0.3014772  -0.4109471  ... -0.37207505 -0.5982823\n  -0.21451849]]\n\n"
    }
   ],
   "source": [
    "# Path of model\n",
    "MODEL_PATH = './homework/DNN.h5'\n",
    "\n",
    "# Reading model\n",
    "print(\"Reading model:\")\n",
    "with h5py.File(MODEL_PATH, 'r') as f:\n",
    "    dense = f['/model_weights/dense/dense']\n",
    "    dense_bias = dense['bias:0'][0]\n",
    "    dense_kernel = dense['kernel:0'][:]\n",
    "\n",
    "    dense_1 = f['/model_weights/dense_1/dense_1']\n",
    "    dense_1_bias = dense_1['bias:0'][0]\n",
    "    dense_1_kernel = dense_1['kernel:0'][:]\n",
    "\n",
    "    dense_2 = f['/model_weights/dense_2/dense_2']\n",
    "    dense_2_bias = dense_2['bias:0'][0]\n",
    "    dense_2_kernel = dense_2['kernel:0'][:]\n",
    "\n",
    "print(\"Matrix of dense_0_bias：\\n%s\\n\"%dense_bias)\n",
    "print(\"Matrix of dense_0_kernel：\\n%s\\n\"%dense_kernel)\n",
    "print(\"Matrix of dense_1_bias：\\n%s\\n\"%dense_1_bias)\n",
    "print(\"Matrix of dense_1_kernel：\\n%s\\n\"%dense_1_kernel)\n",
    "print(\"Matrix of dense_2_bias：\\n%s\\n\"%dense_2_bias)\n",
    "print(\"Matrix of dense_2_kernel：\\n%s\\n\"%dense_2_kernel)"
   ]
  }
 ]
}